{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HARI_TEXT_SUMM5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP11SuCSPlLRcUX9hX055oT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harikrishnangit/MINI-PROJECT/blob/main/HARI_TEXT_SUMM5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input text article\n",
        "article_text= \"linguistic expression, such as the English example The quick brown fox jumps over the lazy dog. In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. In non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. In functional linguistics, it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods, question marks, and exclamation marks. This notion contrasts with a curve, which is delimited by phonologic features such as pitch and loudness and markers such as pauses; and with a clause, which is a sequence of words that represents some process going on throughout time \""
      ],
      "metadata": {
        "id": "MAcQNWsx7pZe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Modules"
      ],
      "metadata": {
        "id": "UgcEuYTp8upI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "mfMpgs8d7zJb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "ndc4bXv-8wKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = article_text.lower()\n",
        "article_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "rXjpQ0rU8o65",
        "outputId": "0792bbaa-03dc-447e-ac02-674196c826b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'linguistic expression, such as the english example the quick brown fox jumps over the lazy dog. in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. in functional linguistics, it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods, question marks, and exclamation marks. this notion contrasts with a curve, which is delimited by phonologic features such as pitch and loudness and markers such as pauses; and with a clause, which is a sequence of words that represents some process going on throughout time '"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove spaces, punctuations and numbers\n",
        "clean_text = re.sub('[^a-zA-Z]', ' ', article_text)\n",
        "clean_text = re.sub('\\s+', ' ', clean_text)\n",
        "clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "O8xGMePa85KH",
        "outputId": "8635dc9a-2f4a-4a43-e910-3279e3a75596"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'linguistic expression such as the english example the quick brown fox jumps over the lazy dog in traditional grammar it is typically defined as a string of words that expresses a complete thought or as a unit consisting of a subject and predicate in non functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent in functional linguistics it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods question marks and exclamation marks this notion contrasts with a curve which is delimited by phonologic features such as pitch and loudness and markers such as pauses and with a clause which is a sequence of words that represents some process going on throughout time '"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up-MVnmG9SmJ",
        "outputId": "6871688f-6294-45ba-ec10-e5158dee26a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into sentence list\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "sentence_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1WOsuN29Utu",
        "outputId": "a1ec0101-6169-450d-f086-8ccde955d3cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['linguistic expression, such as the english example the quick brown fox jumps over the lazy dog.',\n",
              " 'in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.',\n",
              " 'in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent.',\n",
              " 'in functional linguistics, it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods, question marks, and exclamation marks.',\n",
              " 'this notion contrasts with a curve, which is delimited by phonologic features such as pitch and loudness and markers such as pauses; and with a clause, which is a sequence of words that represents some process going on throughout time']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## run this cell once to download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jywNZNYf9YNJ",
        "outputId": "c3a3e1b7-1adc-48a7-e3db-a0820d3b62de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1cSmuLv99hbP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Frequencies"
      ],
      "metadata": {
        "id": "1tyk3Vur9myO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(clean_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies:\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "metadata": {
        "id": "OsdS1Uae9nwG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_frequency = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies:\n",
        "    word_frequencies[word] = word_frequencies[word] / maximum_frequency"
      ],
      "metadata": {
        "id": "vtsrcBIx9sdu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Sentence Scores"
      ],
      "metadata": {
        "id": "AaifDNLu9ySe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = {}\n",
        "\n",
        "for sentence in sentence_list:\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        if word in word_frequencies and len(sentence.split(' ')) < 30:\n",
        "            if sentence not in sentence_scores:\n",
        "                sentence_scores[sentence] = word_frequencies[word]\n",
        "            else:\n",
        "                sentence_scores[sentence] += word_frequencies[word]"
      ],
      "metadata": {
        "id": "_GdN7Xn69zPl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM2PTOYq96g1",
        "outputId": "0f295f03-3d08-4c87-f2c3-04fd2e0011d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'brown': 0.3333333333333333,\n",
              " 'case': 0.3333333333333333,\n",
              " 'clause': 0.3333333333333333,\n",
              " 'complete': 0.3333333333333333,\n",
              " 'consisting': 0.3333333333333333,\n",
              " 'constituent': 0.3333333333333333,\n",
              " 'contrasts': 0.3333333333333333,\n",
              " 'curve': 0.3333333333333333,\n",
              " 'defined': 1.0,\n",
              " 'delimited': 0.6666666666666666,\n",
              " 'dog': 0.3333333333333333,\n",
              " 'english': 0.3333333333333333,\n",
              " 'example': 0.3333333333333333,\n",
              " 'exclamation': 0.3333333333333333,\n",
              " 'expresses': 0.3333333333333333,\n",
              " 'expression': 0.3333333333333333,\n",
              " 'features': 0.6666666666666666,\n",
              " 'fox': 0.3333333333333333,\n",
              " 'functional': 0.6666666666666666,\n",
              " 'going': 0.3333333333333333,\n",
              " 'grammar': 0.3333333333333333,\n",
              " 'graphological': 0.3333333333333333,\n",
              " 'jumps': 0.3333333333333333,\n",
              " 'lazy': 0.3333333333333333,\n",
              " 'letters': 0.3333333333333333,\n",
              " 'linguistic': 0.3333333333333333,\n",
              " 'linguistics': 0.6666666666666666,\n",
              " 'loudness': 0.3333333333333333,\n",
              " 'markers': 0.6666666666666666,\n",
              " 'marks': 0.6666666666666666,\n",
              " 'maximal': 0.3333333333333333,\n",
              " 'non': 0.3333333333333333,\n",
              " 'notion': 0.3333333333333333,\n",
              " 'pauses': 0.3333333333333333,\n",
              " 'periods': 0.3333333333333333,\n",
              " 'phonologic': 0.3333333333333333,\n",
              " 'pitch': 0.3333333333333333,\n",
              " 'predicate': 0.3333333333333333,\n",
              " 'process': 0.3333333333333333,\n",
              " 'question': 0.3333333333333333,\n",
              " 'quick': 0.3333333333333333,\n",
              " 'represents': 0.3333333333333333,\n",
              " 'sequence': 0.3333333333333333,\n",
              " 'string': 0.3333333333333333,\n",
              " 'structure': 0.3333333333333333,\n",
              " 'subject': 0.3333333333333333,\n",
              " 'syntactic': 0.3333333333333333,\n",
              " 'texts': 0.3333333333333333,\n",
              " 'thought': 0.3333333333333333,\n",
              " 'throughout': 0.3333333333333333,\n",
              " 'time': 0.3333333333333333,\n",
              " 'traditional': 0.3333333333333333,\n",
              " 'typically': 0.6666666666666666,\n",
              " 'unit': 1.0,\n",
              " 'upper': 0.3333333333333333,\n",
              " 'words': 0.6666666666666666,\n",
              " 'written': 0.3333333333333333}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODAz6YwJ99xl",
        "outputId": "a6e08206-1976-4c6c-d348-b1182355e115"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent.': 4.666666666666666,\n",
              " 'in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate.': 6.333333333333332,\n",
              " 'linguistic expression, such as the english example the quick brown fox jumps over the lazy dog.': 3.3333333333333335}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "EJsNHTHx-JDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "summary = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "print(\" \".join(summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KANMA43T-LU2",
        "outputId": "c46a3879-b65c-460f-a6ec-539a33f77375"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. linguistic expression, such as the english example the quick brown fox jumps over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU scoring"
      ],
      "metadata": {
        "id": "mna1Y2BIDZVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "article_text= ['linguistic expression, such as the English example The quick brown fox jumps over the lazy dog. In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. In non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. In functional linguistics, it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods, question marks, and exclamation marks. This notion contrasts with a curve, which is delimited by phonologic features such as pitch and loudness and markers such as pauses; and with a clause, which is a sequence of words that represents some process going on throughout time']\n",
        "summary= ['in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. linguistic expression, such as the english example the quick brown fox jumps over the lazy dog.']\n",
        "score = corpus_bleu(article_text, summary)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKjyMcjZcLKm",
        "outputId": "90204e0b-ff1b-4f20-918b-4f5ca7a46324"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5339784398794585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word count"
      ],
      "metadata": {
        "id": "BPu_BOoNHaC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "article_text = \"linguistic expression, such as the English example The quick brown fox jumps over the lazy dog. In traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. In non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. In functional linguistics, it is defined as a unit of written texts delimited by graphological features such as upper case letters and markers such as periods, question marks, and exclamation marks. This notion contrasts with a curve, which is delimited by phonologic features such as pitch and loudness and markers such as pauses; and with a clause, which is a sequence of words that represents some process going on throughout time\"\n",
        "summary=\"in traditional grammar, it is typically defined as a string of words that expresses a complete thought, or as a unit consisting of a subject and predicate. in non-functional linguistics it is typically defined as a maximal unit of syntactic structure such as a constituent. linguistic expression, such as the english example the quick brown fox jumps over the lazy dog\"\n",
        "# using regex (findall()) function\n",
        "res = len(re.findall(r'\\w+', article_text))\n",
        "# total no of words\n",
        "print (\"The number of words in input : \" + str(res))\n",
        "res1 = len(re.findall(r'\\w+', summary))\n",
        "# total no of words\n",
        "print (\"The number of words in output : \" + str(res1))"
      ],
      "metadata": {
        "id": "k1OmpE-7PgGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3eb2fc9-530b-4e6a-c27e-509afeff51e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words in input : 133\n",
            "The number of words in output : 62\n"
          ]
        }
      ]
    }
  ]
}